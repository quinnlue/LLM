{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aed98cf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import string\n",
    "import re\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "44765542",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet(r\"cleaned_test.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "23628efc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "23767"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1d4e9ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "80812824",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import string\n",
    "import re\n",
    "import time\n",
    "from collections import Counter\n",
    "from collections import defaultdict\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "\n",
    "allowed_chars = set(string.ascii_letters + string.digits + string.punctuation + \" \\n\\t\")\n",
    "\n",
    "# df = pd.read_parquet(r'wikitext\\wikitext-103-raw-v1\\train-00000-of-00002.parquet')\n",
    "# df = df[df['text'].str.strip() != \"\"].reset_index(drop=True)\n",
    "# df['text'] = df['text'].apply(lambda x: ''.join(c for c in x if c in allowed_chars))\n",
    "\n",
    "# def fix_spaces(text):\n",
    "#     return re.sub(r'\\s+([,.!?;:])', r'\\1', text)\n",
    "\n",
    "# df[\"text\"] = df[\"text\"].apply(fix_spaces)\n",
    "# df[\"text\"] = df[\"text\"].str.replace(\" @-@ \", \"-\", regex=False)\n",
    "\n",
    "\n",
    "# df.to_parquet(\"cleaned_test.parquet\")\n",
    "\n",
    "# df = pd.read_parquet(\"cleaned_test.parquet\")\n",
    "# df = df.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "\n",
    "\n",
    "def filter_text(text):\n",
    "    return ''.join(ch for ch in text if ch in allowed_chars)\n",
    "\n",
    "def get_most_common_pair(seq):\n",
    "    counts = defaultdict(int)\n",
    "    for i in range(len(seq) - 1):\n",
    "        pair = (seq[i], seq[i+1])\n",
    "        counts[pair] += 1\n",
    "    return max(counts, key=counts.get)\n",
    "\n",
    "def update_seq(seq, pair):\n",
    "    new_seq = []\n",
    "    i = 0\n",
    "    while i < len(seq):\n",
    "        if i < len(seq) - 1 and (seq[i], seq[i+1]) == pair:\n",
    "\n",
    "            new_seq.append(''.join(pair))\n",
    "            i += 2\n",
    "        else:\n",
    "            new_seq.append(seq[i])\n",
    "            i += 1\n",
    "    return new_seq\n",
    "\n",
    "def train_bpe(text, num_merges):\n",
    "    i = 0\n",
    "    mapping = defaultdict(int)\n",
    "    # for char in allowed_chars:\n",
    "    #     mapping[char] = i\n",
    "    #     i += 1\n",
    "\n",
    "    for _ in range(num_merges):\n",
    "        pair = get_most_common_pair(text)\n",
    "        text = update_seq(text, pair)\n",
    "        mapping[pair[0]+pair[1]] = i\n",
    "        i += 1\n",
    "    return mapping\n",
    "\n",
    "def encode(text, token_to_id):\n",
    "    out = []\n",
    "    current = \"\"\n",
    "    for i, char in enumerate(text):\n",
    "        print(i)\n",
    "        if current + char in token_to_id:\n",
    "            print(\"continuing, \", current + char)\n",
    "            current += char\n",
    "        else:\n",
    "            print(\"appending, \", current)\n",
    "            out.append(token_to_id[current])\n",
    "            current = char\n",
    "    out.append(token_to_id[current])\n",
    "    return out\n",
    "\n",
    "def decode(token_ids, id2tok):\n",
    "    out = \"\"\n",
    "    for i in token_ids:\n",
    "        out += id2tok[i]\n",
    "    return out\n",
    "\n",
    "\n",
    "\n",
    "# with open(r'tokenizer\\token_to_id.json', 'w') as f:\n",
    "#     json.dump(token_to_id, f)\n",
    "\n",
    "# with open(r'tokenizer\\merges.json', 'w') as f:\n",
    "#     json.dump([list(pair) for pair in merges], f)\n",
    "\n",
    "text = \"hello hero help!\"\n",
    "\n",
    "tok2id = train_bpe(text, num_merges=10)\n",
    "id2tok = {v: k for k, v in tok2id.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "2ab4ca50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(int,\n",
       "            {'he': 0,\n",
       "             'hel': 1,\n",
       "             'o ': 2,\n",
       "             'hell': 3,\n",
       "             'hello ': 4,\n",
       "             'hello he': 5,\n",
       "             'hello her': 6,\n",
       "             'hello hero ': 7,\n",
       "             'hello hero hel': 8,\n",
       "             'hello hero help': 9,\n",
       "             '': 0,\n",
       "             'r': 0,\n",
       "             'p': 0,\n",
       "             '!': 0})"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tok2id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "c47afed0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'he', 1: 'hel', 2: 'o ', 3: 'hell', 4: 'hello '}"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "id2tok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "37314f34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 h\n",
      "1 e\n",
      "2 l\n",
      "3 l\n",
      "4 o\n",
      "5  \n",
      "6 h\n",
      "7 e\n",
      "8 r\n",
      "9 o\n",
      "10  \n",
      "11 h\n",
      "12 e\n",
      "13 l\n",
      "14 p\n",
      "15 !\n"
     ]
    }
   ],
   "source": [
    "for i, char in enumerate(\"hello hero help!\"):\n",
    "    print(i, char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6307c42d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
