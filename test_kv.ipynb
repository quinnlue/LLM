{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "066723a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA not available\n",
      "CUDA not available\n"
     ]
    }
   ],
   "source": [
    "import sys, pathlib\n",
    "sys.path.append(str(pathlib.Path(r\"c:\\ml-projects\").resolve()))\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# Add dlx to path\n",
    "sys.path.insert(0, r'c:\\ml-projects\\dlx')\n",
    "\n",
    "# Force NumPy backend\n",
    "import dlx.utils.backend as backend_module\n",
    "import numpy as np\n",
    "from dlx.nn.optim import AdamW\n",
    "from dlx.nn.tensor import Tensor\n",
    "backend_module.xp = np\n",
    "\n",
    "# Now import\n",
    "from training.model import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "6e64c61d",
   "metadata": {},
   "outputs": [],
   "source": [
    "VOCAB_SIZE = 6\n",
    "D_MODEL = 4\n",
    "N_HEADS = 2\n",
    "MAX_SEQ_LEN = 18\n",
    "PAD_IDX = 0\n",
    "DEPTH = 3\n",
    "temperature = 1.0\n",
    "top_k = None\n",
    "\n",
    "model = Model(\n",
    "    vocab_size=VOCAB_SIZE,\n",
    "    d_model=D_MODEL,\n",
    "    max_seq_len=MAX_SEQ_LEN,\n",
    "    pad_idx=PAD_IDX,\n",
    "    n_heads=N_HEADS,\n",
    "    transformer_depth=DEPTH,\n",
    "    checkpoint_interval_seconds=3600,\n",
    "    train_dir=\"\",\n",
    "    validation_dir=\"\",\n",
    "    checkpoint_dir=\"\",\n",
    "    epochs=1,\n",
    "    mini_batch_per_step=8\n",
    ")\n",
    "x = np.array([[4, 3, 0, 5]], dtype=np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "ed506758",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tensor(data=[[[ 0.5821211   0.14637749 -0.01239725  0.23310004 -0.95350814\n",
       "   -0.58259827]\n",
       "  [-2.0239506  -1.7800325  -0.17124878  0.27141005  2.1315334\n",
       "    1.6554675 ]\n",
       "  [-1.9380119  -1.6958257  -0.17536205  0.2407715   2.0849853\n",
       "    1.5957426 ]\n",
       "  [ 0.123274   -1.0422896  -0.9044097  -0.47731978  1.1892995\n",
       "    0.44133627]]], shape=(1, 4, 6), dtype=float32)"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.forward(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "dbaa7354",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4 3 0 5 4]]\n",
      "[[4 3 0 5 4 1]]\n",
      "[[4 3 0 5 4 1 1]]\n",
      "[[4 3 0 5 4 1 1 1]]\n",
      "[[4 3 0 5 4 1 1 1 1]]\n",
      "[[4 3 0 5 4 1 1 1 1 0]]\n",
      "[[4 3 0 5 4 1 1 1 1 0 5]]\n",
      "[[4 3 0 5 4 1 1 1 1 0 5 5]]\n",
      "[[4 3 0 5 4 1 1 1 1 0 5 5 4]]\n",
      "[[4 3 0 5 4 1 1 1 1 0 5 5 4 4]]\n"
     ]
    }
   ],
   "source": [
    "idx = x.copy()\n",
    "for _ in range(10):\n",
    "    logits = model.forward(idx)\n",
    "    logits = logits[:, -1, :]\n",
    "    logits = logits / temperature\n",
    "    logits_np = logits.data[0]\n",
    "    if top_k is not None:\n",
    "        top_k_idx = np.argpartition(logits_np, -top_k)[-top_k:]\n",
    "        mask = np.full_like(logits_np, -float('inf'))\n",
    "        mask[top_k_idx] = logits_np[top_k_idx]\n",
    "        logits_np = mask\n",
    "    \n",
    "    # Sample max probability\n",
    "    probs = np.exp(logits_np - np.max(logits_np))\n",
    "    probs = probs / np.sum(probs)\n",
    "    next_token = np.argmax(probs)\n",
    "    \n",
    "    # Append to sequence\n",
    "    next_token_array = np.array([[next_token]], dtype=np.int32)\n",
    "    idx = np.concatenate([idx, next_token_array], axis=1)\n",
    "    print(idx)\n",
    "    \n",
    "\n",
    "    current_position += 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "426eb10d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4 3 0 5 4]]\n",
      "[[4 3 0 5 4 1]]\n",
      "[[4 3 0 5 4 1 1]]\n",
      "[[4 3 0 5 4 1 1 1]]\n",
      "[[4 3 0 5 4 1 1 1 1]]\n",
      "[[4 3 0 5 4 1 1 1 1 0]]\n",
      "[[4 3 0 5 4 1 1 1 1 0 5]]\n",
      "[[4 3 0 5 4 1 1 1 1 0 5 5]]\n",
      "[[4 3 0 5 4 1 1 1 1 0 5 5 4]]\n",
      "[[4 3 0 5 4 1 1 1 1 0 5 5 4 4]]\n"
     ]
    }
   ],
   "source": [
    "idx = x.copy()\n",
    "\n",
    "\n",
    "# kv_cache is of shape (trasnformer_depth, batch_size, max_seq_len, d_model)\n",
    "kv_shape = (DEPTH, 1, MAX_SEQ_LEN, D_MODEL)\n",
    "kv_cache = {\n",
    "    \"k\": Tensor(np.zeros(kv_shape)),\n",
    "    \"v\": Tensor(np.zeros(kv_shape))\n",
    "}\n",
    "\n",
    "\n",
    "for i in range(len(idx[0])):\n",
    "    current_position = i\n",
    "    # print(f\"Print kv cache after {i} tokens (position {current_position}) (in the prompt part of idx)\")\n",
    "    # print(kv_cache)\n",
    "    logits = model.forward(idx[:,:i+1], kv_cache, current_position)\n",
    "\n",
    "\n",
    "for _ in range(10):\n",
    "    # print(f\"Print kv cache after {i} tokens (position {current_position}) (in the generated part of idx)\")\n",
    "    # print(kv_cache)\n",
    "    logits = model.forward(idx, kv_cache, current_position)\n",
    "    logits = logits[:, -1, :]\n",
    "    logits = logits / temperature\n",
    "    logits_np = logits.data[0]\n",
    "    if top_k is not None:\n",
    "        top_k_idx = np.argpartition(logits_np, -top_k)[-top_k:]\n",
    "        mask = np.full_like(logits_np, -float('inf'))\n",
    "        mask[top_k_idx] = logits_np[top_k_idx]\n",
    "        logits_np = mask\n",
    "    \n",
    "    # Sample from distribution\n",
    "    probs = np.exp(logits_np - np.max(logits_np))\n",
    "    probs = probs / np.sum(probs)\n",
    "    next_token = np.argmax(probs)\n",
    "    \n",
    "    # Append to sequence\n",
    "    next_token_array = np.array([[next_token]], dtype=np.int32)\n",
    "    idx = np.concatenate([idx, next_token_array], axis=1)\n",
    "    print(idx)\n",
    "    \n",
    "\n",
    "    current_position += 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eac4e47",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
